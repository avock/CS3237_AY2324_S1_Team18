{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "J2FxrIwRvg7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMbniEc4vjDR",
        "outputId": "cdbc4c53-7bea-4b45-fce6-73d756280bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "ref                                                         title                                             size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "----------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "iamsouravbanerjee/customer-shopping-trends-dataset          Customer Shopping Trends Dataset                 146KB  2023-10-05 06:45:37          21786        455  1.0              \n",
            "samyakb/student-stress-factors                              Student stress factors                            887B  2023-11-02 12:42:11           2390         56  0.9411765        \n",
            "nelgiriyewithana/billionaires-statistics-dataset            Billionaires Statistics Dataset (2023)           139KB  2023-09-29 13:39:28          11976        288  1.0              \n",
            "joebeachcapital/30000-spotify-songs                         30000 Spotify Songs                                3MB  2023-11-01 06:06:43           2097         53  1.0              \n",
            "prasad22/healthcare-dataset                                 Healthcare Dataset                               483KB  2023-10-31 11:30:58           1529         34  1.0              \n",
            "rajatkumar30/fake-news                                      Fake News Prediction Dataset                      11MB  2023-11-03 17:26:38            702         29  1.0              \n",
            "nelgiriyewithana/world-educational-data                     World Educational Data                             9KB  2023-11-04 06:10:17           1439         44  1.0              \n",
            "mahmoudshogaa/us-crime-rates-1960-2014                      US_Crime_Rates_1960_2014                           3KB  2023-10-28 03:50:46           1115         26  1.0              \n",
            "purusinghvi/email-spam-classification-dataset               Spam Email Classification Dataset                 43MB  2023-11-06 10:43:38            467         24  1.0              \n",
            "thedrcat/daigt-proper-train-dataset                         DAIGT Proper Train Dataset                       119MB  2023-11-05 14:03:25            384         72  1.0              \n",
            "rajatkumar30/streaming-application-viewership               Streaming Application                            471KB  2023-10-20 22:12:06            745         23  1.0              \n",
            "rajatsurana979/fast-food-sales-report                       Restaurant Sales report                          122KB  2023-11-06 20:46:39           1292         37  1.0              \n",
            "zeesolver/consumer-behavior-and-shopping-habits-dataset     Consumer Behavior and Shopping Habits Dataset:   146KB  2023-10-19 13:36:26           4205         65  1.0              \n",
            "adeolaadesina/factors-affecting-children-anemia-level       Factors Affecting Children Anemia Level          258KB  2023-10-26 13:13:02           1318         25  1.0              \n",
            "sujaykapadnis/hollywood-hits-and-flops-2007-2023            Hollywood Hits and Flops [2007 - 2023]           204KB  2023-10-26 13:04:38           1262         34  1.0              \n",
            "anshika2301/hr-analytics-dataset                            HR Analytics Dataset                             209KB  2023-10-27 14:57:47           1237         30  1.0              \n",
            "victorahaji/worlds-air-quality-and-water-pollution-dataset  World's Air Quality and Water Pollution Dataset   58KB  2023-10-30 12:37:47           2210         45  0.9411765        \n",
            "jonwright13/ufo-sightings-around-the-world-better           UFO Sightings Around The World (Better)            5MB  2023-10-25 14:08:19            632         25  0.9411765        \n",
            "amirmahdiabbootalebi/salary-by-job-title-and-country        Salary by Job Title and Country                   37KB  2023-11-02 06:37:13           1192         32  1.0              \n",
            "anshtanwar/monthly-food-price-estimates                     Global Food Price Inflation                      254KB  2023-10-21 15:33:25           6671        104  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download -d sarjit07/hand-gesture-recog-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InJ6u29DvlqB",
        "outputId": "3a77f6e5-6daa-4876-f353-996686468e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading hand-gesture-recog-dataset.zip to /content\n",
            "100% 42.9M/42.9M [00:03<00:00, 22.5MB/s]\n",
            "100% 42.9M/42.9M [00:03<00:00, 14.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('hand-gesture-recog-dataset.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "naEMsMZFvuz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # We'll be storing our data as numpy arrays\n",
        "import os # For handling directories\n",
        "from PIL import Image # For handling the images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg # Plotting"
      ],
      "metadata": {
        "id": "kGycwru_BM2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-cPdqS-uyrm",
        "outputId": "7793c86d-940c-4717-d0c1-31c0bacf5528"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/data/thumbsup',\n",
              " '/content/data/ok',\n",
              " '/content/data/blank',\n",
              " '/content/data/thumbsdown',\n",
              " '/content/data/five',\n",
              " '/content/data/fist']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Loading the Dataset\n",
        "\n",
        "DATASET_PATH = '/content/data'\n",
        "\n",
        "dataset_path = os.path.join(DATASET_PATH, '*')\n",
        "import glob\n",
        "dataset_path = glob.glob(dataset_path)\n",
        "dataset_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "image = cv2.imread('/content/data/five/hand1(1015).jpg')\n",
        "image = cv2.resize(image,(100, 120))\n",
        "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "UF6QwLl5vIh5",
        "outputId": "d27101b4-855d-4f3c-f2bf-67ad39991b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7985bff4f520>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_images = []\n",
        "\n",
        "list_of_gestures = ['blank', 'fist', 'five']\n",
        "\n",
        "# to convert the image to grayscale for CNN model training\n",
        "for path in range(0, 3):\n",
        "    dataset_path = \"/content/data/\" + str(list_of_gestures[path])\n",
        "    gesture_path = os.path.join(dataset_path, '*')\n",
        "    import glob\n",
        "    gest_path = glob.glob(gesture_path)\n",
        "    k = 0\n",
        "    for i in range(0, len(gest_path)):\n",
        "        if k < 1600:\n",
        "            image = cv2.imread(gest_path[i])\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            gray_image = cv2.resize(gray_image,(100, 120))\n",
        "            loaded_images.append(gray_image)\n",
        "        k=k+1\n",
        "print(len(loaded_images))\n",
        "\n",
        "y_data = []\n",
        "\n",
        "for i in range(3):\n",
        "  for j in range(1600):\n",
        "    y_data.append(i)\n",
        "\n",
        "print(len(y_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNbJM4iEvTI0",
        "outputId": "7f30500d-4009-4fac-df44-693d727f4cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4800\n",
            "4800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.asarray(loaded_images)\n",
        "x = x.reshape((4800, 1, 120, 100))\n",
        "y = np.asarray(y_data)\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr9SNVCW_mPi",
        "outputId": "5d616318-e128-433b-c9c8-985a554c13ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4800, 1, 120, 100)\n",
            "(4800,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "3OfKpTJuveVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_data_tensor = torch.Tensor(x)\n",
        "y_data_tensor = torch.Tensor(y).to(torch.int64)"
      ],
      "metadata": {
        "id": "qfaq6lJ5EQ6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# to split dataset into training and testing sets\n",
        "x_train,x_test,y_train,y_test = train_test_split(x_data_tensor,y_data_tensor,test_size = 0.3)"
      ],
      "metadata": {
        "id": "HOaorW_sC4ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset = TensorDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 64)\n",
        "\n",
        "train_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GQuLaLqC5Yh",
        "outputId": "cc4981af-7be6-4ec3-e00c-70b216cdde94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7984fd777460>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNModel(nn.Module):\n",
        "    def __init__(self): # class constructor function\n",
        "\n",
        "        super(CNNModel, self).__init__() # initialize an instance of the parent class\n",
        "\n",
        "        # first convolutional and maxpool layer\n",
        "        # input 1x120x100, output 16x116x96\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size=(5, 5))\n",
        "        # input 16x116x96, output 16x58x48\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "        # second convolutional and maxpool layer\n",
        "        # input 16x58x48, output 32x54x44\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(5, 5))\n",
        "        # input 32x54x44, output 32x27x22\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "\n",
        "        # linear layer\n",
        "        self.fc1 = nn.Linear(in_features=19008, out_features=120)\n",
        "        self.fc2 = nn.Linear(120,84)\n",
        "        self.fc3 = nn.Linear(84,3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Layer 1\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        # Layer 2\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        # Output Fully Connected Layers\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        output = x\n",
        "\n",
        "        # return the output predictions\n",
        "        return output\n",
        "\n",
        "model = CNNModel()"
      ],
      "metadata": {
        "id": "LJnGWKny-36o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define training hyperparameters\n",
        "lr = 1e-2 # learning rate\n",
        "num_epochs = 50 # number of epochs\n",
        "\n",
        "# set the device we will be using to train the model (to enable hardware acceleration)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss function\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9) # optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "for e in range(0, num_epochs):\n",
        "\t# set the model in training mode\n",
        "\tmodel.train()\n",
        "\n",
        "  # initialize the total training and validation loss\n",
        "\ttotalTrainLoss = 0\n",
        "\n",
        "  # initialize the number of correct predictions in the training\n",
        "\t# and validation step\n",
        "\ttrainCorrect = 0\n",
        "\n",
        "  # loop over the training set\n",
        "\tfor i, (x, y) in enumerate(train_loader):\n",
        "\n",
        "    # send the input to the device\n",
        "\t\t(x, y) = (x.to(device), y.to(device))\n",
        "\n",
        "\t\tpred = model(x) # forward pass\n",
        "\t\tloss = criterion(pred, y) # compute training loss\n",
        "\n",
        "\t\toptimizer.zero_grad() # zero out the gradients\n",
        "\t\tloss.backward() # perform backpropagation step\n",
        "\t\toptimizer.step() # update weights\n",
        "\n",
        "\t\t# calculate the number of correct predictions\n",
        "\t\ttotalTrainLoss += loss # add the loss to the cumulative training loss\n",
        "\tprint(\"Epoch\", e, \"Training Loss:\", totalTrainLoss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzozLxFR-4VZ",
        "outputId": "91238723-aaa9-4200-f5de-41f307efaf04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Training Loss: 529.3844604492188\n",
            "Epoch 1 Training Loss: 10.585504531860352\n",
            "Epoch 2 Training Loss: 3.550658941268921\n",
            "Epoch 3 Training Loss: 1.1858636140823364\n",
            "Epoch 4 Training Loss: 0.46529069542884827\n",
            "Epoch 5 Training Loss: 0.8197588920593262\n",
            "Epoch 6 Training Loss: 0.34876748919487\n",
            "Epoch 7 Training Loss: 0.12606610357761383\n",
            "Epoch 8 Training Loss: 0.07592780888080597\n",
            "Epoch 9 Training Loss: 0.008394180797040462\n",
            "Epoch 10 Training Loss: 0.0021778112277388573\n",
            "Epoch 11 Training Loss: 0.0015005990862846375\n",
            "Epoch 12 Training Loss: 0.0011776882456615567\n",
            "Epoch 13 Training Loss: 0.0009585160296410322\n",
            "Epoch 14 Training Loss: 0.0007998263463377953\n",
            "Epoch 15 Training Loss: 0.0006805239245295525\n",
            "Epoch 16 Training Loss: 0.0005877163494005799\n",
            "Epoch 17 Training Loss: 0.0005139040295034647\n",
            "Epoch 18 Training Loss: 0.0004540436202660203\n",
            "Epoch 19 Training Loss: 0.0004045404784847051\n",
            "Epoch 20 Training Loss: 0.00036308704875409603\n",
            "Epoch 21 Training Loss: 0.0003278452786616981\n",
            "Epoch 22 Training Loss: 0.0002975727547891438\n",
            "Epoch 23 Training Loss: 0.00027163431514054537\n",
            "Epoch 24 Training Loss: 0.0002490652841515839\n",
            "Epoch 25 Training Loss: 0.00022867912775836885\n",
            "Epoch 26 Training Loss: 0.00021152275439817458\n",
            "Epoch 27 Training Loss: 0.0001955322950379923\n",
            "Epoch 28 Training Loss: 0.0001826710649766028\n",
            "Epoch 29 Training Loss: 0.00017129050684161484\n",
            "Epoch 30 Training Loss: 0.00015972000255715102\n",
            "Epoch 31 Training Loss: 0.00015018526755739003\n",
            "Epoch 32 Training Loss: 0.00014147198817227036\n",
            "Epoch 33 Training Loss: 0.00013315728574525565\n",
            "Epoch 34 Training Loss: 0.00012460790458135307\n",
            "Epoch 35 Training Loss: 0.00011777208419516683\n",
            "Epoch 36 Training Loss: 0.00011166829062858596\n",
            "Epoch 37 Training Loss: 0.0001060133654391393\n",
            "Epoch 38 Training Loss: 0.00010067511175293475\n",
            "Epoch 39 Training Loss: 9.577082528267056e-05\n",
            "Epoch 40 Training Loss: 8.992034418042749e-05\n",
            "Epoch 41 Training Loss: 8.571641228627414e-05\n",
            "Epoch 42 Training Loss: 8.172853267751634e-05\n",
            "Epoch 43 Training Loss: 7.799398008501157e-05\n",
            "Epoch 44 Training Loss: 7.445500523317605e-05\n",
            "Epoch 45 Training Loss: 7.119540532585233e-05\n",
            "Epoch 46 Training Loss: 6.802334974054247e-05\n",
            "Epoch 47 Training Loss: 6.495374691439793e-05\n",
            "Epoch 48 Training Loss: 6.211696745594963e-05\n",
            "Epoch 49 Training Loss: 5.9380781749496236e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "model.eval() # enable model evaluation mode\n",
        "correct_sum_train = 0\n",
        "total_train = 0\n",
        "correct_sum_test = 0\n",
        "total_test = 0\n",
        "with torch.no_grad():\n",
        "  for i, (data, target) in enumerate(train_loader):\n",
        "\n",
        "    # send the input to the device\n",
        "    (data, target) = (data.to(device), target.to(device))\n",
        "    output = model(data)\n",
        "\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # _, target = torch.max(target, 1)\n",
        "\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target)\n",
        "    correct = np.squeeze(correct_tensor)\n",
        "\n",
        "    # calculate train accuracy\n",
        "    correct_sum_train += correct.sum().item()\n",
        "    total_train += target.size(0)\n",
        "\n",
        "\n",
        "correct_count = np.sum(correct_sum_train)\n",
        "total_count = np.sum(total_train)\n",
        "train_accuracy =  round(100.0 * (correct_count / total_count), 6)\n",
        "formatted_accuracy = \"{:.6f}\".format(train_accuracy)\n",
        "\n",
        "print(f\"Train Accuracy (Overall): {formatted_accuracy} ({correct_count}/{total_count})\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, (data, target) in enumerate(test_loader):\n",
        "\n",
        "    # send the input to the device\n",
        "    (data, target) = (data.to(device), target.to(device))\n",
        "    output = model(data)\n",
        "\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # _, target = torch.max(target, 1)\n",
        "\n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(target)\n",
        "    correct = np.squeeze(correct_tensor)\n",
        "\n",
        "    # calculate test accuracy\n",
        "    correct_sum_test += correct.sum().item()\n",
        "    total_test += target.size(0)\n",
        "\n",
        "\n",
        "correct_count = np.sum(correct_sum_test)\n",
        "total_count = np.sum(total_test)\n",
        "test_accuracy =  round(100.0 * (correct_count / total_count), 6)\n",
        "formatted_accuracy = \"{:.6f}\".format(test_accuracy)\n",
        "\n",
        "print(f\"Test Accuracy (Overall): {formatted_accuracy} ({correct_count}/{total_count})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgd6J627KAUE",
        "outputId": "836db523-2828-4939-dc1c-2b3956614aa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy (Overall): 100.000000 (3360/3360)\n",
            "Test Accuracy (Overall): 98.958333 (1425/1440)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to save the trained model as .pt file\n",
        "model_save_name = 'handclassifier6.pt'\n",
        "# path = f\"/content/drive/MyDrive/{model_save_name}\"\n",
        "path = f\"/content/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "metadata": {
        "id": "FfO3ce7xe7SL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}